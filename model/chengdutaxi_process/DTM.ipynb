{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, math\n",
    "from pprint import pprint  # pretty-printer\n",
    "from collections import defaultdict\n",
    "from gensim.models import CoherenceModel, LdaModel, LdaMulticore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID        lat         lng  passengers          timestamp\n",
      "0   1  30.624806  104.136604           1  2014/8/3 21:18:46\n",
      "1   1  30.624809  104.136612           1  2014/8/3 21:18:15\n",
      "2   1  30.624811  104.136587           1  2014/8/3 21:20:17\n",
      "3   1  30.624811  104.136596           1  2014/8/3 21:19:16\n",
      "4   1  30.624811  104.136619           1  2014/8/3 21:17:44\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53045407 entries, 0 to 53045406\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   ID          int64  \n",
      " 1   lat         float64\n",
      " 2   lng         float64\n",
      " 3   passengers  int64  \n",
      " 4   timestamp   object \n",
      "dtypes: float64(2), int64(2), object(1)\n",
      "memory usage: 2.0+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "filepath = \"../../data/chengdu_taxi/\"\n",
    "filename = filepath + os.path.join(filepath, '20140803_train.txt')\n",
    "dataset = pd.read_csv(filename, header=None, names=[\"ID\", \"lat\", \"lng\", \"passengers\", \"timestamp\"])\n",
    "print(dataset.head())\n",
    "print(dataset.info())\n",
    "dataset['timestamp'] = pd.to_datetime(dataset['timestamp'])\n",
    "dataset['hour'] = dataset['timestamp'].dt.hour"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 清空变量内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import gc\n",
    "# del [dataset]\n",
    "# gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 划分区域 生成区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.032468 30.290675 104.609693 103.269638\n"
     ]
    }
   ],
   "source": [
    "# split gird\n",
    "# 1经度111KM\n",
    "\n",
    "def gird_by_span():\n",
    "    #根据框个数划分\n",
    "    column_num, row_num = 200, 200\n",
    "    gird_lat_span = (LATMAX - LATMIN)/row_num\n",
    "    gird_lng_span = (LNGMAX - LNGMIN)/column_num\n",
    "    return gird_lat_span, gird_lng_span, column_num, row_num\n",
    "\n",
    "def gird_by_distance(lng_dis = 0.5, lat_dis = 0.4):\n",
    "    #根据距离划分\n",
    "    #纬度跨度0.4km 经度跨度0.5km\n",
    "    #经纬度距离估算https://blog.csdn.net/weixin_35301706/article/details/112527068\n",
    "\n",
    "    gird_lat_span = 1 / (111 / lat_dis)\n",
    "    gird_lng_span = 1 / ((111 * math.cos( (LATMAX + LATMIN) / 2)) / lng_dis)\n",
    "    row_num = round((LATMAX - LATMIN) / gird_lat_span)\n",
    "    column_num = round((LNGMAX - LNGMIN) / gird_lng_span)\n",
    "    return gird_lat_span, gird_lng_span, column_num, row_num\n",
    "\n",
    "LATMAX, LATMIN, LNGMAX, LNGMIN = np.max(dataset['lat']), np.min(dataset['lat']), np.max(dataset['lng']), np.min(dataset['lng'])\n",
    "print(LATMAX, LATMIN, LNGMAX, LNGMIN)\n",
    "\n",
    "# gird_lat_span, gird_lng_span, column_num, row_num = gird_by_span()\n",
    "gird_lat_span, gird_lng_span, column_num, row_num = gird_by_distance()\n",
    "\n",
    "\n",
    "def LngLat2GirdID(lat,lng):\n",
    "    if lng < LNGMIN or lng > LNGMAX or lat < LATMIN or lat > LATMAX:\n",
    "        return -1\n",
    "\n",
    "    return int((lat-LATMIN)/gird_lat_span) + int((lng-LNGMIN)/gird_lng_span) * column_num \n",
    "\n",
    "\n",
    "def GirdID2LngLat(gird_id):\n",
    "    curr_row = int(gird_id/row_num)\n",
    "    curr_column = gird_id % column_num\n",
    "\n",
    "    return [LATMIN + gird_lat_span * (curr_row + 0.5 ), LNGMIN + gird_lng_span * (curr_column + 0.5)]\n",
    "\n",
    "#划分区域id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['gird_id'] = dataset.apply(lambda x: LngLat2GirdID(x['lat'], x['lng']), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成用于[轨迹-小时-序列]，用于后续生成文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_list = np.unique(dataset['hour'])\n",
    "out_filename_part = '20140803_train_'\n",
    "alltraSequence = pd.DataFrame(columns=['TraID', 'hour', 'sequence'])\n",
    "\n",
    "for i, v in enumerate(hour_list):\n",
    "    traSequence = []\n",
    "    outfile = out_filename_part + str(v) + '.csv'\n",
    "    dataset_sub = dataset.loc[dataset['hour'] == v] \n",
    "    dataset_sub = dataset_sub.groupby([dataset_sub['ID'], dataset_sub['hour']])\n",
    "    \n",
    "    for index, group in dataset_sub:\n",
    "        group_sorted = group.sort_values(['timestamp'], ascending = [True])\n",
    "        traSequence.append([index[0], index[1], group_sorted.gird_id.tolist()])\n",
    "    \n",
    "    traSequence = pd.DataFrame(traSequence, columns=['TraID', 'hour', 'sequence'])\n",
    "    traSequence.to_csv(os.path.join(filepath, outfile), index=False)\n",
    "    \n",
    "    alltraSequence = pd.concat([alltraSequence, traSequence], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltraSequence.to_csv(os.path.join(filepath, '20140803_sequence_full.csv'), index=False) #保存在本地 下次不用再次执行上边代码"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二次运行时可以从这里开始\n",
    "免去数据组织"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from disk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, math\n",
    "from pprint import pprint  # pretty-printer\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "filepath = \"../../data/chengdu_taxi/\"\n",
    "traSequence = pd.read_csv(os.path.join(filepath, '20140803_sequence_full.csv'))\n",
    "traSequence['sequence'] = traSequence['sequence'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct documents texts dicionary corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct documents\n",
    "documents = []\n",
    "for seq in zip(traSequence['sequence']):\n",
    "    my_list = list(seq)[0]\n",
    "    my_list = [str(current) + '-' + str(my_list[idx + 1]) if idx < len(my_list) - 1 else None for idx, current in enumerate(my_list)][: -1]\n",
    "    join_s = \" \"\n",
    "    join_s = join_s.join(my_list)\n",
    "    documents.append(join_s)\n",
    "\n",
    "# construct texts\n",
    "# remove words that appear only once\n",
    "texts = [[word for word in document.lower().split()] for document in documents]\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "texts = [[token for token in text] for text in texts]\n",
    "\n",
    "## dictionary \n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "dictionary = Dictionary(texts)\n",
    "dictionary.save('./tmp/20140803_full.dict')  # store the dictionary, for future reference\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\code\\topic modeling\\tm\\lib\\site-packages\\gensim\\models\\ldaseqmodel.py:297: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  convergence = np.fabs((bound - old_bound) / old_bound)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaSeqModel\n",
    "\n",
    "#find hour corresponding list\n",
    "time_slice = [traSequence.index[traSequence['hour'] == hour][0] for i, hour in enumerate(np.unique(traSequence.hour).tolist())]\n",
    "\n",
    "ldaseq = LdaSeqModel(corpus=corpus, time_slice=time_slice, num_topics=18, chunksize=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('9', 0.13409381204548854),\n",
      "  ('10', 0.11466000998754254),\n",
      "  ('11', 0.09137169443299875),\n",
      "  ('2', 0.07918483111432532),\n",
      "  ('7', 0.07907639383611106),\n",
      "  ('5', 0.07826225346973789),\n",
      "  ('4', 0.07351501667722589),\n",
      "  ('6', 0.07344995495497192),\n",
      "  ('1', 0.07179158725343673),\n",
      "  ('3', 0.07066024824961405),\n",
      "  ('8', 0.0670171042817487),\n",
      "  ('0', 0.06691709369679869)],\n",
      " [('9', 0.13700349156547825),\n",
      "  ('10', 0.1024057730781501),\n",
      "  ('11', 0.08621747235151137),\n",
      "  ('7', 0.08298758428169366),\n",
      "  ('1', 0.08098021999830733),\n",
      "  ('5', 0.07846665965686862),\n",
      "  ('4', 0.07846599097325184),\n",
      "  ('3', 0.07587932552738036),\n",
      "  ('2', 0.07467687658173018),\n",
      "  ('0', 0.07312390221441539),\n",
      "  ('8', 0.07249535749462568),\n",
      "  ('6', 0.05729734627658735)],\n",
      " [('1', 0.22452412555633425),\n",
      "  ('2', 0.22452412555633425),\n",
      "  ('0', 0.13771693207346059),\n",
      "  ('9', 0.047335506369430166),\n",
      "  ('3', 0.04573741380555508),\n",
      "  ('4', 0.04573741380555508),\n",
      "  ('5', 0.04573741380555508),\n",
      "  ('6', 0.04573741380555508),\n",
      "  ('7', 0.04573741380555508),\n",
      "  ('8', 0.04573741380555508),\n",
      "  ('10', 0.04573741380555508),\n",
      "  ('11', 0.04573741380555508)],\n",
      " [('9', 0.13806836879132636),\n",
      "  ('10', 0.10633444888719441),\n",
      "  ('11', 0.09342898672170145),\n",
      "  ('5', 0.08339847313899106),\n",
      "  ('7', 0.07828537897483226),\n",
      "  ('1', 0.07780016004935993),\n",
      "  ('6', 0.07366995780166342),\n",
      "  ('0', 0.07230256658806203),\n",
      "  ('4', 0.07112035638746099),\n",
      "  ('3', 0.07057071294346039),\n",
      "  ('8', 0.06784122749042863),\n",
      "  ('2', 0.06717936222551917)],\n",
      " [('3', 0.1891781324812944),\n",
      "  ('6', 0.1891781324812944),\n",
      "  ('7', 0.1891781324812944),\n",
      "  ('0', 0.12488672401110469),\n",
      "  ('1', 0.03844735981812651),\n",
      "  ('2', 0.03844735981812651),\n",
      "  ('4', 0.03844735981812651),\n",
      "  ('5', 0.03844735981812651),\n",
      "  ('8', 0.03844735981812651),\n",
      "  ('9', 0.03844735981812651),\n",
      "  ('10', 0.03844735981812651),\n",
      "  ('11', 0.03844735981812651)],\n",
      " [('10', 0.15058771959426367),\n",
      "  ('9', 0.12461604571426516),\n",
      "  ('11', 0.08055472803931389),\n",
      "  ('5', 0.07990142318880938),\n",
      "  ('2', 0.07669218763144608),\n",
      "  ('7', 0.07584616133087292),\n",
      "  ('1', 0.07392007784508493),\n",
      "  ('4', 0.07186648531515903),\n",
      "  ('6', 0.06920778288720238),\n",
      "  ('8', 0.06702562382700347),\n",
      "  ('3', 0.06646570683128407),\n",
      "  ('0', 0.06331605779529498)],\n",
      " [('9', 0.16440295683559802),\n",
      "  ('10', 0.10800460803231106),\n",
      "  ('11', 0.08358916218735109),\n",
      "  ('5', 0.08268742835315764),\n",
      "  ('7', 0.0769411204155059),\n",
      "  ('4', 0.07398421956771002),\n",
      "  ('1', 0.07385701110751693),\n",
      "  ('8', 0.07138019084877432),\n",
      "  ('2', 0.0693196552534942),\n",
      "  ('3', 0.06707143786331865),\n",
      "  ('0', 0.06603321297463138),\n",
      "  ('6', 0.06272899656063086)],\n",
      " [('5', 0.5044551012619213),\n",
      "  ('1', 0.1006375880337965),\n",
      "  ('8', 0.1006375880337965),\n",
      "  ('0', 0.09019460758632851),\n",
      "  ('2', 0.025509389385519655),\n",
      "  ('3', 0.025509389385519655),\n",
      "  ('4', 0.025509389385519655),\n",
      "  ('6', 0.025509389385519655),\n",
      "  ('7', 0.025509389385519655),\n",
      "  ('9', 0.025509389385519655),\n",
      "  ('10', 0.025509389385519655),\n",
      "  ('11', 0.025509389385519655)],\n",
      " [('9', 0.128997360863812),\n",
      "  ('10', 0.10269901650571804),\n",
      "  ('5', 0.0931240405929724),\n",
      "  ('11', 0.08665488470044808),\n",
      "  ('7', 0.08208112944128487),\n",
      "  ('1', 0.07602640545657727),\n",
      "  ('8', 0.07435676878938015),\n",
      "  ('6', 0.07370808634116578),\n",
      "  ('2', 0.07337061142903353),\n",
      "  ('3', 0.07197629389056442),\n",
      "  ('0', 0.07056356287929193),\n",
      "  ('4', 0.06644183910975157)],\n",
      " [('9', 0.1616237902737182),\n",
      "  ('11', 0.09723437463655984),\n",
      "  ('10', 0.09114627669434097),\n",
      "  ('5', 0.0836659347808191),\n",
      "  ('4', 0.0752231787821047),\n",
      "  ('6', 0.07373355819501695),\n",
      "  ('0', 0.07359196679781807),\n",
      "  ('8', 0.07156105430103607),\n",
      "  ('2', 0.07127323552385197),\n",
      "  ('7', 0.07016038229252365),\n",
      "  ('1', 0.06602053666628238),\n",
      "  ('3', 0.06476571105592803)],\n",
      " [('9', 0.14672932224832427),\n",
      "  ('10', 0.11082647729723528),\n",
      "  ('11', 0.08609735452125952),\n",
      "  ('5', 0.08384694508464459),\n",
      "  ('7', 0.07945622237584538),\n",
      "  ('6', 0.07892821641655631),\n",
      "  ('1', 0.07415475432410568),\n",
      "  ('2', 0.07360328150021363),\n",
      "  ('4', 0.06915252876948376),\n",
      "  ('3', 0.06653127193907094),\n",
      "  ('0', 0.06597613368345799),\n",
      "  ('8', 0.06469749183980272)],\n",
      " [('3', 0.13046609088023128),\n",
      "  ('4', 0.13046609088023128),\n",
      "  ('5', 0.13046609088023128),\n",
      "  ('6', 0.13046609088023128),\n",
      "  ('7', 0.13046609088023128),\n",
      "  ('0', 0.08386492245604762),\n",
      "  ('1', 0.04396743719046602),\n",
      "  ('2', 0.04396743719046602),\n",
      "  ('8', 0.04396743719046602),\n",
      "  ('9', 0.04396743719046602),\n",
      "  ('10', 0.04396743719046602),\n",
      "  ('11', 0.04396743719046602)],\n",
      " [('9', 0.1278009680118596),\n",
      "  ('10', 0.1272541024577583),\n",
      "  ('7', 0.0833463775904594),\n",
      "  ('5', 0.08284674647392389),\n",
      "  ('4', 0.08117184935074237),\n",
      "  ('11', 0.07567261734314153),\n",
      "  ('8', 0.07210816216765396),\n",
      "  ('2', 0.07201983586531195),\n",
      "  ('0', 0.0718705700609684),\n",
      "  ('6', 0.07104498553749644),\n",
      "  ('1', 0.06849957140300582),\n",
      "  ('3', 0.06636421373767838)],\n",
      " [('9', 0.48526463121742824),\n",
      "  ('10', 0.3316412623836445),\n",
      "  ('11', 0.042653407492347244),\n",
      "  ('0', 0.025782537658942572),\n",
      "  ('1', 0.01433227015595469),\n",
      "  ('2', 0.01433227015595469),\n",
      "  ('3', 0.01433227015595469),\n",
      "  ('4', 0.01433227015595469),\n",
      "  ('5', 0.01433227015595469),\n",
      "  ('6', 0.01433227015595469),\n",
      "  ('7', 0.01433227015595469),\n",
      "  ('8', 0.01433227015595469)],\n",
      " [('9', 0.14443478292137696),\n",
      "  ('10', 0.12274037967651026),\n",
      "  ('5', 0.08486082747153506),\n",
      "  ('2', 0.07782598574255421),\n",
      "  ('7', 0.07611876196687749),\n",
      "  ('4', 0.07531506429467281),\n",
      "  ('1', 0.07466999161726427),\n",
      "  ('8', 0.07103277860595159),\n",
      "  ('11', 0.07101072159634245),\n",
      "  ('6', 0.06870915432341504),\n",
      "  ('0', 0.0684076452645643),\n",
      "  ('3', 0.06487390651893561)],\n",
      " [('10', 0.18961213161756887),\n",
      "  ('4', 0.18829380277506955),\n",
      "  ('11', 0.18829380277506955),\n",
      "  ('0', 0.12489082255949178),\n",
      "  ('9', 0.039785651475485906),\n",
      "  ('1', 0.03844625554247348),\n",
      "  ('2', 0.03844625554247348),\n",
      "  ('3', 0.03844625554247348),\n",
      "  ('5', 0.03844625554247348),\n",
      "  ('6', 0.03844625554247348),\n",
      "  ('7', 0.03844625554247348),\n",
      "  ('8', 0.03844625554247348)],\n",
      " [('2', 0.15295549396838773),\n",
      "  ('5', 0.15295549396838773),\n",
      "  ('7', 0.15295549396838773),\n",
      "  ('8', 0.15295549396838773),\n",
      "  ('0', 0.11678232284149252),\n",
      "  ('1', 0.0387708144692795),\n",
      "  ('3', 0.0387708144692795),\n",
      "  ('4', 0.0387708144692795),\n",
      "  ('6', 0.0387708144692795),\n",
      "  ('9', 0.0387708144692795),\n",
      "  ('10', 0.0387708144692795),\n",
      "  ('11', 0.0387708144692795)],\n",
      " [('9', 0.16080028073200459),\n",
      "  ('10', 0.10889498851025707),\n",
      "  ('11', 0.10435006877317657),\n",
      "  ('1', 0.07670238469436957),\n",
      "  ('5', 0.07455469996312512),\n",
      "  ('3', 0.06977036305537657),\n",
      "  ('2', 0.06972557879484388),\n",
      "  ('8', 0.06949990728767423),\n",
      "  ('4', 0.06927592784745056),\n",
      "  ('7', 0.06706957533031438),\n",
      "  ('0', 0.06682516621180237),\n",
      "  ('6', 0.06253105879960519)]]\n"
     ]
    }
   ],
   "source": [
    "pprint(ldaseq.print_topics(time=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dynamic topic modeling analysis\n",
    "- https://markroxor.github.io/gensim/static/notebooks/ldaseqmodel.html#topic=0&lambda=0.83&term=\n",
    "- Printing Topics\n",
    "- Looking for Topic Evolution\n",
    "- Document - Topic Proportions\n",
    "- Distances between documents\n",
    "- Chain Variance\n",
    "- Topic Coherence for DTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aac8a9a8b5ce27ca47f1a8f48187750109ab89a063f3c0709cdff307e6ebb2e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
