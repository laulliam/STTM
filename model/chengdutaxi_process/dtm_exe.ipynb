{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from disk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, math\n",
    "from pprint import pprint  # pretty-printer\n",
    "from collections import defaultdict\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim import corpora, utils\n",
    "from gensim.models.wrappers.dtmmodel import DtmModel\n",
    "import ast\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = \"../data/chengdu_taxi/\"\n",
    "data_filename = '20140803_sequence_full.csv'\n",
    "traSequence = pd.read_csv(os.path.join(data_filepath, data_filename))\n",
    "# 构造序列停留点检测\n",
    "staypoint = False\n",
    "def get_stay_points(df_col, staypoint):\n",
    "    if staypoint == False:\n",
    "        # 不加入停留点\n",
    "        return df_col.apply(lambda x: [k for k, v in groupby(ast.literal_eval(x))])\n",
    "    elif staypoint == True:\n",
    "        # 加入停留点\n",
    "        return df_col.apply(lambda x: ast.literal_eval(x))\n",
    "traSequence['sequence'] = get_stay_points(traSequence['sequence'], staypoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct documents\n",
    "documents = []\n",
    "for seq in zip(traSequence['sequence']):\n",
    "    my_list = list(seq)[0]\n",
    "    my_list_pair = []\n",
    "    for idx, current in enumerate(my_list):\n",
    "        if len(my_list) == 1:\n",
    "            my_list_pair.append(str(current) + '-' + str(current))\n",
    "        elif idx < len(my_list) - 1:\n",
    "            my_list_pair.append(str(current) + '-' + str(my_list[idx + 1]))\n",
    "    join_s = \" \"\n",
    "    join_s = join_s.join(my_list_pair)\n",
    "    documents.append(join_s)\n",
    "\n",
    "# construct texts\n",
    "# remove words that appear only once\n",
    "texts = [[word for word in document.lower().split()] for document in documents]\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "texts = [[token for token in text] for text in texts]\n",
    "\n",
    "## dictionary\n",
    "\n",
    "dictionary = Dictionary(texts)\n",
    "dictionary.save('./tmp/20140803_full.dict')  # store the dictionary, for future reference\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# store the dictionary, for future reference\n",
    "dict_filepath = \"./tmp/\"\n",
    "dict_filename = 'dict-stay' + str(staypoint) + str(data_filename.split('.')[0]) + '.dict'\n",
    "dictionary.save(os.path.join(dict_filepath, dict_filename))  \n",
    "#corpus = [['id', 'count'], ['id', 'count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DTMcorpus(corpora.textcorpus.TextCorpus):\n",
    "\n",
    "#     def get_texts(self):\n",
    "#         return self.input\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.input)\n",
    "\n",
    "#     def re(self):\n",
    "#         return self\n",
    "\n",
    "# corpus = DTMcorpus(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_list = np.unique(traSequence['hour'])\n",
    "time_slice = [len(traSequence[traSequence['hour'] == hour]) for i, hour in enumerate(hour_list)]\n",
    "model = DtmModel('../utils/dtm-win64.exe', corpus=corpus, id2word=dictionary, time_slices=time_slice, num_topics=18, initialize_lda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the model\n",
    "model_filepath = \"./model/\"\n",
    "model_filename = 'model-stay' + str(staypoint) + str(data_filename.split('.')[0])\n",
    "model.save(os.path.join(model_filepath, model_filename))\n",
    "\n",
    "# Load a potentially pre-trained model from disk.\n",
    "#ldaseq = model.load(os.path.join(model_filepath, model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'False'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staypoint = False\n",
    "str(staypoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71b2a00b800374914640998b59e55b2ea3c384b63099ac801a4d42b188cda674"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
